In this video, we will start learning how to use the Keras library to build deep learning models. We will start with building models for regression problems. In this course, we will be using Cognitive Class Labs, or CC Labs for short, as our platform to run the lab sessions. So if you go to labs.cognitiveclass.ai, you can either sign in if you already have a Cognitive Class account, or sign up if this is your first visit to Cognitive Class or its Labs platform. Once you sign in you should get to this landing page, where you can select different environments. Let's click on JupyterLab to start a new JupyterLab Notebook. Once JupyterLab loads, click on the Python 3 icon to start a new notebook. In order to avoid any technical hiccups, or to make sure that you have the smoothest experience, we have pre-installed the Keras library in CC Labs so you can import it directly by running "import keras". Once the code executes, it will print what backend was used to install the Keras library. Here, we used the TensorFlow backend. Let's take a look at a regression example. Here is a data set of the compressive strength of different samples of concrete based on the volumes of the different materials that were used to make them. So the first concrete sample has 540 cubic meter of cement, 0 cubic meter of blast furnace slag, 0 cubic meter of fly ash, 162 cubic meter of water, 2.5 cubic meter of superplasticizer, 1040 cubic meter of coarse aggregate, and 676 cubic meter of fine aggregate. Such a concrete mix which is 28 days old has a compressive strength of 79.99 MPa. The data is in a pandas dataframe and named concrete_data. So let's say we would like to use the Keras library to quickly build a deep neural network to model this dataset, and so we can automatically determine the compressive strength of a given concrete sample based on its ingredients. So let's say that the deep neural network that we would like to create takes all the eight features as input, feeds them into a hidden layer of five nodes, which is connected to another hidden layer of five nodes, which is then connected to the output layer with one node that is supposed to output the compressive strength of a given concrete sample. Note that usually you would go with a much larger number of neurons in each hidden layer like 50 or even 100, but we're just using a small network for simplicity. Notice how all the nodes in one layer are connected to all the other nodes in the next layer. Such a network is called a dense network. Before we begin using the Keras library, let's prepare our data and have it in the right format. The only thing we would need to do is to split the dataframe into two dataframes, one that has the predictors columns and another one that has the target column. We will also name them predictors and target. Now, prepare to see the magic of Keras and how building such a network and training it and using it to predict new samples can be achieved with only few lines of code. The first thing you will need to do, is import Keras and the Sequential model from "keras.models". Because our network consists of a linear stack of layers, then the Sequential model is what you would want to use. This is the case most of the time unless you are building something out of the ordinary. There are two models in the Keras library. One of them is the Sequential model and the other one is the model class used with the functional API. So to create your model, you simply call the Sequential constructor. Now building your layers is pretty straightforward as well. For that, we would need to import the "Dense" type of layers from "keras.layers". Then we use the add method to add each dense layer. We specify the number of neurons in each layer and the activation function that we want to use. As per our discussion in the video on activation functions, ReLU is one of the recommended activation functions for hidden layers, so we will use that. And for the first hidden layer we need to pass in the "input_shape" parameter, which is the number of columns or predictors in our dataset. Then we repeat the same thing for the other hidden layer, of course without the input_shape parameter, and we create our output layer with one node. Now for training, we need to define an optimizer and the error metric. In the previous module, we used gradient descent as our minimization or optimization algorithm, and the mean squared error as our loss measure between the predicted value and the ground truth. So we will stick with that and use the mean squared error as our loss measure. As for the minimization algorithm, there are actually other more efficient algorithms than the gradient descent for deep learning applications. One of them is "adam". One of the main advantages of the "adam" optimizer is that you don't need to specify the learning rate that we saw in the gradient descent video. So this saves us the task of optimizing the learning rate for our model. Then we use the fit method to train our model. Once training is complete, we can start making predictions using the predict method. Below the video, you will find a document with links to different sections in the Keras library that you can refer to to learn more about optimizers, models, and other methods that you can use in the Keras library. But this code snippet here, is typically all you need to know to build a regression model in Keras. In the next video, we will learn how to build a classification model using the Keras library.